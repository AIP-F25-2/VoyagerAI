{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1564d82f-f92e-4631-bd97-e1084969bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd9dc1b-3ab0-4c52-88c0-a64513411440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: schedule in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be150a8-dcf8-4f0e-8a99-233cd5b1aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: pandas in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from streamlit) (4.25.8)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: jinja2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
      "Requirement already satisfied: colorama in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit pandas requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a2a7a2-4fae-4bff-8b92-c115430779ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (4.13.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pymongo) (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534e1ee-1abe-409e-8b62-f1a614075caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0dc9f74-58bd-45bb-9fcd-97503f064d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efae199-8276-4811-a634-80ca6bee8080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2025.2)\n",
      "Requirement already satisfied: pandas in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from python-dateutil) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\preet\\envs\\sentiment_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-dateutil pytz pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0937183-b83e-4113-aa79-a8965397d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os, re, time, json, hashlib\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser as dtparse\n",
    "import pytz\n",
    "\n",
    "# Config \n",
    "DUBAI_TZ = pytz.timezone(\"Asia/Dubai\")\n",
    "HEADERS = {\"User-Agent\": \"DubaiEventsCSV/1.0 (+respectful scraping; non-bulk)\"}\n",
    "REQ_TIMEOUT = 20\n",
    "PAUSE = 1.1  # politeness delay between HTTP requests\n",
    "EVENTBRITE_TOKEN = os.getenv(\"EVENTBRITE_TOKEN\", \"WJS7O2YA33T2S3UC5U4I\").strip()\n",
    "\n",
    "#  Helpers\n",
    "def now_dubai() -> datetime:\n",
    "    return datetime.now(DUBAI_TZ)\n",
    "\n",
    "def aware_dt(s: Optional[str]) -> Optional[datetime]:\n",
    "    if not s: return None\n",
    "    try:\n",
    "        d = dtparse.parse(s)\n",
    "        if d.tzinfo is None: d = DUBAI_TZ.localize(d)\n",
    "        else: d = d.astimezone(DUBAI_TZ)\n",
    "        return d\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_iso(d: Optional[datetime]) -> Optional[str]:\n",
    "    return d.isoformat() if d else None\n",
    "\n",
    "def make_uid(parts) -> str:\n",
    "    base = \"|\".join([p or \"\" for p in parts])\n",
    "    return hashlib.sha1(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def norm_row(source, source_id, title, start_dt, end_dt,\n",
    "             url=None, venue=None, address=None, city=\"Dubai\", country=\"UAE\",\n",
    "             status=\"scheduled\", category=None, organizer=None, price=None, image=None) -> Dict:\n",
    "    uid = make_uid([source, str(source_id or \"\"), title or \"\", to_iso(start_dt) or \"\"])\n",
    "    return {\n",
    "        \"uid\": uid,\n",
    "        \"source\": source,\n",
    "        \"source_id\": str(source_id or \"\"),\n",
    "        \"title\": (title or \"\").strip(),\n",
    "        \"start\": to_iso(start_dt),\n",
    "        \"end\": to_iso(end_dt),\n",
    "        \"status\": status,\n",
    "        \"url\": url,\n",
    "        \"venue\": venue,\n",
    "        \"address\": address,\n",
    "        \"city\": city,\n",
    "        \"country\": country,\n",
    "        \"category\": category,\n",
    "        \"organizer\": organizer,\n",
    "        \"price\": price,\n",
    "        \"image\": image,\n",
    "        \"ingested_at\": to_iso(now_dubai()),\n",
    "    }\n",
    "\n",
    "def keep_future_or_ongoing(row: Dict) -> bool:\n",
    "    now = now_dubai()\n",
    "    s = aware_dt(row.get(\"start\")) if row.get(\"start\") else None\n",
    "    e = aware_dt(row.get(\"end\")) if row.get(\"end\") else None\n",
    "    if s and s >= now: return True\n",
    "    if e and e >= now: return True\n",
    "    if s and s.date() == now.date(): return True\n",
    "    return False\n",
    "\n",
    "def dedupe(rows: List[Dict]) -> List[Dict]:\n",
    "    seen, out = set(), []\n",
    "    for r in rows:\n",
    "        if r[\"uid\"] in seen: continue\n",
    "        seen.add(r[\"uid\"]); out.append(r)\n",
    "    return out\n",
    "\n",
    "# Eventbrite \n",
    "def fetch_eventbrite_dubai() -> List[Dict]:\n",
    "    rows = []\n",
    "    if not EVENTBRITE_TOKEN: return rows\n",
    "    url = \"https://www.eventbriteapi.com/v3/events/search/\"\n",
    "    params = {\n",
    "        \"q\": \"Dubai\",\n",
    "        \"location.address\": \"Dubai\",\n",
    "        \"expand\": \"venue,category,organizer,logo\",\n",
    "        \"sort_by\": \"date\",\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {EVENTBRITE_TOKEN}\"}\n",
    "    page = 1\n",
    "    while True:\n",
    "        params[\"page\"] = page\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=REQ_TIMEOUT)\n",
    "        if r.status_code != 200: break\n",
    "        data = r.json()\n",
    "        evs = data.get(\"events\", [])\n",
    "        if not evs: break\n",
    "        for ev in evs:\n",
    "            title = (ev.get(\"name\") or {}).get(\"text\")\n",
    "            start = aware_dt((ev.get(\"start\") or {}).get(\"utc\"))\n",
    "            end   = aware_dt((ev.get(\"end\") or {}).get(\"utc\"))\n",
    "            venue = (ev.get(\"venue\") or {}).get(\"name\")\n",
    "            address = None\n",
    "            if ev.get(\"venue\") and ev[\"venue\"].get(\"address\"):\n",
    "                a = ev[\"venue\"][\"address\"]\n",
    "                address = \", \".join([a.get(k) for k in [\"address_1\",\"address_2\",\"city\",\"region\",\"postal_code\"] if a.get(k)])\n",
    "            url_e = ev.get(\"url\")\n",
    "            category = (ev.get(\"category\") or {}).get(\"name\")\n",
    "            organizer = (ev.get(\"organizer\") or {}).get(\"name\")\n",
    "            image = (ev.get(\"logo\") or {}).get(\"url\")\n",
    "            rows.append(norm_row(\"eventbrite\", ev.get(\"id\"), title, start, end, url_e, venue, address,\n",
    "                                 category=category, organizer=organizer, image=image))\n",
    "        page += 1\n",
    "        time.sleep(PAUSE)\n",
    "    return rows\n",
    "\n",
    "# Visit Dubai \n",
    "def parse_visitdubai_card(card) -> Optional[Dict]:\n",
    "    a = card.select_one(\"a[href]\")\n",
    "    if not a: return None\n",
    "    href = a[\"href\"]\n",
    "    url = \"https://www.visitdubai.com\" + href if href.startswith(\"/\") else href\n",
    "    title_el = card.select_one(\"h3, h2\"); title = title_el.get_text(strip=True) if title_el else None\n",
    "\n",
    "    date_text = None\n",
    "    for sel in [\".card__date\", \".event-card__date\", \".c-card__date\", \".date\", \"[data-test='date']\"]:\n",
    "        el = card.select_one(sel)\n",
    "        if el: date_text = el.get_text(\" \", strip=True); break\n",
    "\n",
    "    start_dt = end_dt = None\n",
    "    if date_text:\n",
    "        parts = re.split(r\"\\s*[-–—]\\s*\", date_text)\n",
    "        try:\n",
    "            if len(parts) == 2:\n",
    "                start_dt = aware_dt(parts[0] + \" \" + str(datetime.now().year))\n",
    "                end_dt = aware_dt(parts[1])\n",
    "                if end_dt and start_dt and end_dt < start_dt:\n",
    "                    start_dt = aware_dt(parts[0] + \" \" + str(end_dt.year))\n",
    "            else:\n",
    "                start_dt = aware_dt(date_text)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    venue_el = card.select_one(\".event-card__venue, .venue, .c-card__subtitle\")\n",
    "    venue = venue_el.get_text(\" \", strip=True) if venue_el else None\n",
    "\n",
    "    img_el = card.select_one(\"img[src], img[data-src]\")\n",
    "    image = (img_el.get(\"src\") or img_el.get(\"data-src\")) if img_el else None\n",
    "\n",
    "    return norm_row(\"visitdubai\", url, title or \"Event\", start_dt, end_dt, url, venue, None, image=image)\n",
    "\n",
    "def fetch_visitdubai(max_pages: int = 5) -> List[Dict]:\n",
    "    rows = []\n",
    "    base = \"https://www.visitdubai.com/en/whats-on/dubai-events\"\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = base if page == 1 else f\"{base}?page={page}\"\n",
    "        r = requests.get(url, headers=HEADERS, timeout=REQ_TIMEOUT)\n",
    "        if r.status_code != 200: break\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        cards = soup.select(\"article, .event-card, .c-card, li a[href*='/en/whats-on/']\")\n",
    "        if not cards: cards = soup.select(\"a[href*='/en/whats-on/']\")\n",
    "        for c in cards:\n",
    "            row = parse_visitdubai_card(c)\n",
    "            if row: rows.append(row)\n",
    "        time.sleep(PAUSE)\n",
    "    return rows\n",
    "\n",
    "# Platinumlist \n",
    "def parse_platinum_card(card) -> Optional[Dict]:\n",
    "    a = card.select_one(\"a[href]\")\n",
    "    if not a: return None\n",
    "    href = a[\"href\"]\n",
    "    url = \"https://dubai.platinumlist.net\" + href if href.startswith(\"/\") else href\n",
    "    title_el = card.select_one(\"h3, h2, .event-card-title, .title\")\n",
    "    title = title_el.get_text(\" \", strip=True) if title_el else None\n",
    "    date_el = card.select_one(\".date, .event-card-date, time\")\n",
    "    date_text = date_el.get_text(\" \", strip=True) if date_el else None\n",
    "\n",
    "    start_dt = end_dt = None\n",
    "    if date_text:\n",
    "        parts = re.split(r\"\\s*[-–—]\\s*\", date_text)\n",
    "        try:\n",
    "            if len(parts) == 2:\n",
    "                start_dt = aware_dt(parts[0] + \" \" + str(datetime.now().year))\n",
    "                end_dt = aware_dt(parts[1])\n",
    "                if end_dt and start_dt and end_dt < start_dt:\n",
    "                    start_dt = aware_dt(parts[0] + \" \" + str(end_dt.year))\n",
    "            else:\n",
    "                start_dt = aware_dt(date_text)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    venue_el = card.select_one(\".venue, .event-card-venue, [data-qa='venue-name']\")\n",
    "    venue = venue_el.get_text(\" \", strip=True) if venue_el else None\n",
    "    img_el = card.select_one(\"img[src], img[data-src]\")\n",
    "    image = (img_el.get(\"src\") or img_el.get(\"data-src\")) if img_el else None\n",
    "\n",
    "    return norm_row(\"platinumlist\", url, title or \"Event\", start_dt, end_dt, url, venue, None, image=image)\n",
    "\n",
    "def fetch_platinumlist(max_pages: int = 5) -> List[Dict]:\n",
    "    rows = []\n",
    "    base = \"https://dubai.platinumlist.net/event\"\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = base if page == 1 else f\"{base}?page={page}\"\n",
    "        r = requests.get(url, headers=HEADERS, timeout=REQ_TIMEOUT)\n",
    "        if r.status_code != 200: break\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        cards = soup.select(\"article, .event-card, .event-card--item, li a[href*='/event/']\")\n",
    "        if not cards: cards = soup.select(\"a[href*='/event/']\")\n",
    "        for c in cards:\n",
    "            row = parse_platinum_card(c)\n",
    "            if row: rows.append(row)\n",
    "        time.sleep(PAUSE)\n",
    "    return rows\n",
    "\n",
    "#  Runner \n",
    "def run(csv_path: str = \"dubai_events.csv\", include_eventbrite: bool = True, pages: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Scrape Dubai events and write to CSV. Returns the DataFrame.\"\"\"\n",
    "    all_rows: List[Dict] = []\n",
    "\n",
    "    # Eventbrite \n",
    "    if include_eventbrite and EVENTBRITE_TOKEN:\n",
    "        try:\n",
    "            all_rows.extend(fetch_eventbrite_dubai())\n",
    "        except Exception as e:\n",
    "            print(\"Eventbrite fetch failed:\", e)\n",
    "\n",
    "    # VisitDubai + Platinumlist\n",
    "    try:\n",
    "        all_rows.extend(fetch_visitdubai(max_pages=pages))\n",
    "    except Exception as e:\n",
    "        print(\"VisitDubai fetch failed:\", e)\n",
    "\n",
    "    try:\n",
    "        all_rows.extend(fetch_platinumlist(max_pages=pages))\n",
    "    except Exception as e:\n",
    "        print(\"Platinumlist fetch failed:\", e)\n",
    "\n",
    "    # De-dupe + keep upcoming/ongoing\n",
    "    all_rows = dedupe(all_rows)\n",
    "    filtered = [r for r in all_rows if keep_future_or_ongoing(r)]\n",
    "\n",
    "    # DataFrame + sort + CSV\n",
    "    df = pd.DataFrame(filtered, columns=[\n",
    "        \"uid\",\"source\",\"source_id\",\"title\",\"start\",\"end\",\"status\",\"url\",\"venue\",\n",
    "        \"address\",\"city\",\"country\",\"category\",\"organizer\",\"price\",\"image\",\"ingested_at\"\n",
    "    ])\n",
    "\n",
    "    def _safe_dt(x):\n",
    "        try: return dtparse.parse(x) if pd.notna(x) else None\n",
    "        except Exception: return None\n",
    "    df[\"start_dt_sort\"] = df[\"start\"].apply(_safe_dt)\n",
    "    df = df.sort_values(by=[\"start_dt_sort\",\"title\"], ascending=[True, True]).drop(columns=[\"start_dt_sort\"])\n",
    "\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"Saved {len(df)} events to {csv_path}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66b713-4d8d-4840-9096-d61acebb1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb047d-d28b-419c-9659-0c28e49266e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84065f-39ab-4da7-9309-1b94e8e1977a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentiment_env]",
   "language": "python",
   "name": "conda-env-sentiment_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
